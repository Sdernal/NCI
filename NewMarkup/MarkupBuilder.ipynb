{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import xml.etree.cElementTree as ET\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = os.listdir(\"../coropus_for_korzun/\")\n",
    "files.sort()\n",
    "Time = '{http://www.abbyy.com/ns/Time#}'\n",
    "rdfs = '{http://www.w3.org/2000/01/rdf-schema#}'\n",
    "Aux = '{http://www.abbyy.com/ns/Aux#}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA = []\n",
    "TOKENS = []\n",
    "INDEXES = []\n",
    "LABELS = []\n",
    "prev_sent_num = 0\n",
    "\n",
    "for fl in files:\n",
    "    XML_FILE = os.path.join(\"../coropus_for_korzun\", fl)\n",
    "\n",
    "    tree = ET.ElementTree(file = XML_FILE)\n",
    "    root = tree.getroot()\n",
    "    dates = set()\n",
    "    for child in root:\n",
    "        if child.tag == Time + 'PointOfTime' or child.tag == Time + 'TimeInterval':\n",
    "            children = child.getchildren()     \n",
    "#             label = child.find(rdfs+'label')           \n",
    "#             if label != None:                   \n",
    "#                 dates.add(label.text) \n",
    "# #             else:\n",
    "#                 try:\n",
    "#                     dates.add(children[0].text)\n",
    "#                 except Exception as e:  \n",
    "#                     print(e)\n",
    "            flag = False;       \n",
    "            for part in children:            \n",
    "                if part.tag == Time + 'month' or part.tag == Time + 'day' or part.tag == Time + 'year':\n",
    "                    flag = True\n",
    "                    break\n",
    "            if flag == True:\n",
    "                label = child.find(rdfs+'label')           \n",
    "                if label != None:                   \n",
    "                    dates.add(label.text) \n",
    "                else:\n",
    "                    dates.add(children[0].text)\n",
    "    text = root.find(Aux+'TextAnnotations').find(Aux+'document_text').text\n",
    "#     print(dates)\n",
    "\n",
    "    sentences = sent_tokenize(text.replace('\\u2028', ' '))\n",
    "    words_by_sentence = []\n",
    "    for sentence in sentences:\n",
    "        words_by_sentence.append(word_tokenize(sentence))\n",
    "\n",
    "    splitted_dates = []\n",
    "    for date in dates:\n",
    "        splitted_dates.append(word_tokenize(date))     \n",
    "#     print(words_by_sentence)\n",
    "\n",
    "\n",
    "    labels_by_sentence = []\n",
    "    indexes_by_sentence = []\n",
    "    for w in range(len(words_by_sentence)):\n",
    "        words = words_by_sentence[w]\n",
    "        indexes = len(words)*[prev_sent_num+w] \n",
    "        labels = len(words)*['NONE']\n",
    "        for i in range(len(words)):\n",
    "            for j in range(len(splitted_dates)):\n",
    "                if words[i] == splitted_dates[j][0] and labels[i] =='NONE':\n",
    "                    date_length = len(splitted_dates[j])\n",
    "                    flag = True\n",
    "                    for k in range(date_length):\n",
    "                        try:\n",
    "                            if words[i+k] != splitted_dates[j][k]:\n",
    "                                flag = False\n",
    "                        except Exception as e:\n",
    "                            flag = False\n",
    "                    if flag == True:\n",
    "                        if date_length == 1:\n",
    "                            labels[i] = 'D_OR'\n",
    "                        else:\n",
    "                            labels[i] = 'D_ST'\n",
    "                            for k in range(len(splitted_dates[j]) - 1 ):\n",
    "                                labels[i+1+k] = 'D_PT'\n",
    "                            labels[i+len(splitted_dates[j]) - 1] = 'D_EN'\n",
    "        indexes_by_sentence.append(indexes)\n",
    "        labels_by_sentence.append(labels)\n",
    "    prev_sent_num+=len(words_by_sentence)\n",
    "\n",
    "    # print(indexes_by_sentence)\n",
    "    # print(labels_by_sentence)\n",
    "\n",
    "    \n",
    "    for i in range(len(indexes_by_sentence)):\n",
    "        for j in range(len(indexes_by_sentence[i])):\n",
    "            DATA.append([words_by_sentence[i][j], indexes_by_sentence[i][j]])\n",
    "            TOKENS.append(words_by_sentence[i][j])\n",
    "            INDEXES.append(indexes_by_sentence[i][j])\n",
    "            LABELS.append(labels_by_sentence[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= DATA, index = LABELS)                        \n",
    "df.to_csv('dates.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
